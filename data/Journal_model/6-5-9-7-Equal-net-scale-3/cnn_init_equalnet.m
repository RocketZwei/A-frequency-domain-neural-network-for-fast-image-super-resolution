function net = cnn_init_equalnet(varargin)
opts.batchNormalization = true ;
opts.networkType = 'dagnn' ;
opts.cudnnWorkspaceLimit = 1024*1024*1204 ;
opts = vl_argparse(opts, varargin) ;

rng('default');
rng(0) ;

f=1/1000 ;
net = dagnn.DagNN() ;

lastAdded.var = 'input' ;
maxnumlayer = 6;
gua_size = 5;
defaultdepth = 9;
ht_ksize = 7; % spatial kernel size

input_size = [360 480];
lr_order = 5;
batchSize = 35 ;

lastAdded.depth = defaultdepth ;

fprintf('compute HTmatrix, p-inv matrix\n')
global htmatrix; 
htmatrix = HTmatrix(input_size(1),input_size(2),[ht_ksize ht_ksize]);
global htmatrix_back; 
htmatrix_back = pinv(htmatrix);


function fftConv(name, ht_ksize, ksize, depth, varargin)
% Helper function to add a Convolutional + BatchNorm + ReLU
% sequence to the network.
  args.gua_conv = true ;
  args.bias = false ;
  args.batchNorm = false;
  args = vl_argparse(args, varargin) ;
  
  stride = 1 ;
  
  if args.bias, pars = {[name '_fft'], [name '_b']} ; else pars = {[name '_fft']} ; end
  
  % TODO 
  % depth should be in poiscale
  net.addLayer([name  '_fftconv'], ...
               dagnn.HTScale('wsize', [input_size defaultdepth], 'kernel_size', [ht_ksize ht_ksize]), ...
               lastAdded.var, ...
               [name '_fftconv'], ...
               pars) ;
           
           
  
    lastAdded.var = [name '_fftconv'] ;
    lastAdded.depth = defaultdepth ;
    if args.gua_conv
    net.addLayer([name '_guaconv'] , ...
                 dagnn.Conv('size', [ksize ksize lastAdded.depth 1], ...
                          'stride', stride, ....
                          'pad', (ksize - 1) / 2, ...
                          'hasBias', false, ...
                          'opts', {'cudnnworkspacelimit', opts.cudnnWorkspaceLimit}), ...
                 lastAdded.var, ...
                 [name '_guaconv'], ...
                 [name '_filter']) ;
    lastAdded.var = [name '_guaconv'] ;
    end
%     if args.gua_conv
%     net.addLayer([name '_guaconv1'] , ...
%                  dagnn.Conv('size', [ksize 1 lastAdded.depth 1], ...
%                           'stride', stride, ....
%                           'pad', [(ksize-1)/2,(ksize-1)/2,0,0], ...
%                           'hasBias', false, ...
%                           'opts', {'cudnnworkspacelimit', opts.cudnnWorkspaceLimit}), ...
%                  lastAdded.var, ...
%                  [name '_guaconv1'], ...
%                  [name '_filter1']) ;
%     net.addLayer([name '_guaconv2'] , ...
%                  dagnn.Conv('size', [1 ksize lastAdded.depth 1], ...
%                           'stride', stride, ....
%                           'pad', [0,0,(ksize-1)/2,(ksize-1)/2], ...
%                           'hasBias', false, ...
%                           'opts', {'cudnnworkspacelimit', opts.cudnnWorkspaceLimit}), ...
%                  lastAdded.var, ...
%                  [name '_guaconv2'], ...
%                  [name '_filter2']) ;
%     
%     net.addLayer([name '_guaconv'],...
%             dagnn.Sum(),...
%             {[name '_guaconv1'],[name '_guaconv2']},...
%             [name '_guaconv']);
%     lastAdded.var = [name '_guaconv'];
%     end
  lastAdded.depth = 1 ;
end

for numlayer = 1:maxnumlayer
fftConv(['conv' num2str(numlayer)], ht_ksize, gua_size, defaultdepth, ...
     'gua_conv', true, ...
     'bias', false,...
     'batchNorm', false) ;
end


net.addLayer(['sum_' 'conv'],...
            dagnn.Sum(),...
            {['conv1' '_guaconv'],...
             ['conv2' '_guaconv'],...
             ['conv3' '_guaconv'],...
             ['conv4' '_guaconv'],...
             ['conv5' '_guaconv'],...
             ['conv6' '_guaconv']},...
            ['sum']);
lastAdded.var = ['sum'];

fftConv('prediction', ht_ksize, 1,1, ...
     'gua_conv', true, ...
     'bias', false) ;

net.addLayer('loss', ...
             dagnn.myloss('loss','l2') ,...
             {lastAdded.var, 'label'}, ...
             'objective') ; 

% training parameters
net.meta.trainOpts.numEpochs = 200 ;
net.meta.trainOpts.learningRate = logspace(-lr_order,-lr_order-1, net.meta.trainOpts.numEpochs);
net.meta.trainOpts.batchSize = batchSize ;



% initialize network parameters
net.initParams() ;


end
